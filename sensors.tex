\chapter{Sensor effects}

The LSST camera is being constructed at SLAC National Accelerator Laboratory. Its design was motivated by both survey requirements as well as the need to keep with a strict delivery schedule. To this end, a modular design was adopted to enable assembly and testing of individual components in parallel in a test-as-you-build fashion, as well as to allow for the ability to quickly isolate any issues or defects without disturbing the rest of the focal plane.

The camera design is primarily driven by the LSST Camera system and Focal Plane requirements. The fully assembled camera must satisfy these specifications in order to achieve the precision and accuracy needed for scientific analysis. The survey's speed requirements include reaching the 5$\sigma$ limiting magnitudes given in Table \ref{tab:5sigma} in each of the six filter bands. In addition, each patch in the survey footprint will be imaged every three to four nights (in each band?) (LSST system science requirements document, Ivezic). It is therefore essential to minimize the amount of downtime between exposures by enabling a rapid readout of the focal plane. Thus the entire 3.2 gigapixel focal plane will ultimately be read out in two seconds. This is enabled by a CCD pixel architecture consisting of 4k x 4k 10 $\mu m$ square pixels and 16 independent amplifier segments, allowing for a pixel digitization rate of 0.5 MHz.

% Survey depth in each band
% source:  (IVT of LSST Camera Roodman)
\begin{table}
\caption{LSST survey depth requirements.}
\label{tab:5sigma}
\centering
\begin{tabular}{|c|c|c|}
  \hline
  Band & 5$\sigma$ depth per visit & 5$\sigma$ depth over 10 year survey\\
  \hline \hline
  u & 23.9 & 26.1 \\
  \hline
  g & 25.0 & 27.4 \\
  \hline
  r & 24.7 & 27.5 \\
  \hline
  i & 24.0 & 26.8 \\
  \hline
  z & 23.3 & 26.1 \\
  \hline
  y & 22.1 & 24.9 \\
  \hline
\end{tabular}
\end{table}\\


The LSST focal plane consists of 189 CCDs arranged on 21 autonomous cameras called Raft Tower Modules (RTM). An RTM, along with its associated mechanical, thermal and electronic support components, consists of a square matrix of nine CCDs. In addition to the 21 science rafts, there are four additional corner rafts made up of wavefront sensing and guiding arrays used for focusing and telescope guiding.

Although construction of the LSST camera is taking place at SLAC, initial testing of the CCDs and raft assembly begins at Brookhaven National Laboratory (BNL). Once the rafts are completed, they are shipped to SLAC where the results of a similar suite of tests are compared to those obtained at BNL for consistency.

Verification of camera components was performed on a number of testing benches located in the Camera Clean Room at SLAC. I specifically analyzed data from an optical testing bench called Test Stand 8 (TS8), which was used to perform acceptance tests on individual rafts. A subset of the LSST Camera system requirements are shown in Table \ref{tab:cam-req}. TS8 used a 300 Watt Xe arc lamp, a monochromator, a 6-position filter wheel, an OAP feed optic, a 300 millimeter integrating sphere and a 1 meter baffled dark box (LSST Integration & Test subsystem Bond) to produce dark images, flat fields, $^{55}$Fe X-ray sources, and multi-spot images to study noise, linearity, gain, cross-talk, dead pixels, as well as other unexpected instrument signatures. These electro-optical performance tests were run using a software package developed at SLAC called \pkg{eotest}.  I used the \pkg{eotest} package to study bias corrections and characterize irregularities in the LSST sensors. Because they were produced by two different vendors, Imaging Technology Laboratory (ITL) and Teledyne e2v (e2v), the CCDs have their own unique signatures due to differences in the manufacturing process. A careful study of sensor effects therefore involved evaluating data from TS8 at the raft, CCD, amplifier and vendor level.

 The time I spent at SLAC coincided with the Integration \& Verification Testing phase of the camera construction process, where rafts from BNL were being unpacked from crates and initial verification tests were being performed.

% Focal plane requirements
% source:  (IVT of LSST Camera Roodman)
\begin{table}
\caption{A subset of LSST Focal Plane requirements.}
\label{tab:cam-req}
\centering
\begin{tabular}{|c|c|c|}
  \hline
  Title & Requirement & Test \\
  \hline \hline
  QE & $>$ 41\%, 78\%, 83\%, 82\%, 75\%, 21\% (u,g,r,i,z,y) & Cam. Calib. wide-beam \\
  \hline
  CCD Diffusion & $\sigma < 5\mu m$ & $^{55}$Fe \\
  \hline
  Read Noise & $< 9e^{-}$ & Bias images \\
  \hline
  Linearity & $<3\%$ & Flat-fields\\
  \hline
\end{tabular}
\end{table}\\

\section{Bias and offset corrections}

Every CCD image that is taken contains a bulk offset that must be subtracted out prior to analysis. This offset level, or bias, can be thought of as a ``zero-point'', and typically contains around 20,000 counts. It is usually measured from the serial overscan region of a single channel in a CCD. The overscan region does not refer to a physical location on the sensor. Rather, this region contains ‘virtual’ pixels that are the result of continuing the readout process after data from the last physical pixel in the serial register has been recorded. 

% Include image showing CCD architecture and overscan regions

% How were bias images obtained? What was a typical sequence?
This offset correction is done using bias images, which are a zero-second exposures taken with the shutter closed. % what type of noise do we expect to see in a bias image?

I first looked at bias images to study the performance of various methods of offset correction at the raft, sensor and amplifier level. I then integrated two new offset-correction methods into the EOTest software package, which is a set of acquisition and analysis scripts used to test the electro-optical performance of the Raft Tower Modules (RTMs). A bias image is a zero-second exposure taken with the shutter closed, so it should contain nothing - no light and no dark current - except for the bulk offset level. At the start of my project, the EOTest package had two ways to calculate the offset level. One was to measure the offset as the mean of all the pixels in the serial overscan region, and the other was to fit a low-order polynomial function to the mean per row in the overscan region. I compared these two methods to three other offset-correction methods: calculating the offset as the mean-per-row in the overscan, as a Gaussian process fit and finally as a cubic spline fit to the mean per row in the overscan region. These comparisons can be seen in Fig. []

While the row-by-row correction did the best at characterizing variations in the offset level, it introduced correlated noise of around 10/sqrt(50) ~ 1.4 counts per pixel. The cubic spline fit generally did well at fitting the shape of the mean-per-row without adding a significant amount of extra noise. However its performance varied depending on the sensor vendor (it tended to perform better on e2v sensors), as well as on how well the parameters of the spline fit were adjusted. For example, in some cases, a cubic spline would tend to overfit the data for certain amplifiers, but when the smoothing factor was increased it would come at the cost of losing peaks or dips in the mean-per-row, particularly in the first 50 or so rows. I tried modeling the offset as a gaussian process to see if it would lead to an improvement, but it actually performed worse at fitting the mean-per-row than the cubic spline did. 

I modified the EOTest package to allow the option to apply a mean-per-row or cubic spline offset correction in addition to the existing mean and polynomial fit functions. After carefully studying these methods and applying them to images from TS8, it was decided that the best way to proceed in terms of the current testing software would be to use the mean-per-row method because, even though it introduces slightly more noise, it is significantly more accurate in the lower rows and would suffice for general performance testing. In the end I made this the default offset-correction method for all electro-optical performance tasks in EOTest.

Once the offset level is subtracted and the image is trimmed to remove the overscan region, the next step is to remove the bias. The bias is the pixel-to-pixel structure in the read noise in an image. This structure varies from amplifier to amplifier, as well as across a single amplifier in a CCD. To correct for the bias, a ‘super bias’ is generated for each amplifier by stacking many bias frames that have been offset-corrected and trimmed. I added the functionality in EOTest to be able to stack a set of images according to a statistic (for example, median-stacking or taking a clipped mean of the stacked images), as well as a method to create a ‘super bias’ file, which generates a FITS file containing a super bias for each amplifier for a given raft, sensor and run number. 

Next, I did a study of how well the super bias corrected for the bias level. For a given raft, sensor and run number, I first needed to visually confirm each bias image that would be going into the super bias. I verified all bias images taken during each acquisition mode, which included flat fields, superflats, dark images, quantum efficiency, and an Fe55 source, by plotting serial and parallel projections of each offset-corrected bias image minus the super bias. This amounted to over-plotting the mean of each row/column in every bias minus super bias image against each row/column. I also plotted the mean and sigma over all bias images as a function of row and column. The mean over all biases is expected to be zero and the sigma is expected to be approximately constant, so that bias structure changes would appear as the mean deviating from zero or sigma varying as a function of row or column. Most of the bias images were consistent with what was expected, however there was some peculiar behavior in sigma as a function of row where I observed random oscillations that varied slowly in time. This is something I did not have a chance to investigate thoroughly, but one potential cause to be investigated is banding, which has been observed in some ITL sensors as a row-wise effect where one can see bands going across the image that vary in bias level. 

Projecting the bias in this way revealed an effect called persistence. Several of the corrected bias frames taken during the flat acquisition had mean values as high as 80 counts. Since flat images are taken at increasingly higher exposure times, they detect more light the longer they are exposed. Bias images are taken after every two or three flats, so plotting the timestamp of each flat and bias image showed the outlier bias image as the final bias frame taken during this acquisition. Looking at a projection plot of the flat taken just before this bias image showed the flat to be saturated. It turned out that the excessively high mean value in the outlier bias image was due to charge that had persisted from the previous flat image due to insufficient clearing of the CCD. In this case, more time needed to be allowed between parallel pixel transfers during readout. 

Once all bias images that showed anomalous behavior were removed, I created a super bias for all amplifiers on the sensor from 50 bias images. To study the performance of these super biases, I conducted a ‘ratio test’ using images taken from the superflat acquisition. Superflats were taken in two modes, with low superflats taken to have around 1000 counts, and high superflats having around 50,000 counts. 

The ratio I used to study the super biases was defined as the sum over all bias and offset-corrected low superflats divided by the sum over all bias and offset-corrected high superflats. Because this is essentially a ratio of images, it is immune to any effects like bad pixels or quantum efficiency, which would effectively be divided out. I made a series of two-dimensional histograms of this ratio against the super bias for a number of ITL and e2v rafts. Since the same super bias image is being subtracted from the numerator and the denominator, we would expect the mean of the ratio to be around 1000/50,000 = 0.02 counts, with a sigma of around 0.008. It is also expected that the histogram of the super bias image would have the highest density around zero counts, since the super bias is offset-corrected and should only contain pixel to pixel variations in the noise level. 

The results showed a surprising amount of structure in the super biases, particularly in the ITL sensors. For example, there were ‘clumps’ of points in the super bias that were concentrated in circular lobes at various intervals along the super bias axis. There were also large concentrations of points in the super bias that had values that deviated significantly from zero. On the ratio axis, there were also separate ‘clumps’ of points, most of which were still centered around 0.02, but some of which had slightly lower or higher mean values. After mapping these questionable pixels onto their physical location on the sensor, most either corresponded to bad columns or to the first few columns of an amplifier. This behavior clearly indicates that something is not correct in the way the super bias is being subtracted, and that there may be pixels that should be masked but are being excluded by the current masking selection process in the EOTest code. The e2v sensors were in general more well-behaved, except for a vertical ‘gap’ around a super bias value of zero, where pixels in the super bias were not being plotted. I verified that these super bias images were indeed masked, so the gaps do not seem to be due to bad masking. But I have yet to investigate whether stacking the super bias using a clipped mean rather than the median would fix this issue. 

Lastly, I studied another issue known as bias trending, which was observed by plotting the mean of the imaging section of all bias images in a run over time. Theoretically, a bias image should only contain the offset level, the bias level and the read noise, the last two of which are sub-dominant. This should make the mean stable around 20,000 counts. However this was not the case and there were significant fluctuations in the mean. My work showed that doing a proper bias and offset correction resolved this instability.

\section{Modeling sky brightness in the ImSim package}
\section{Simulating the brighter-fatter effect}

- weak lensing shear requirements, distortion signal from BF

%%% Local Variables: ***
%%% mode: latex ***
%%% TeX-master: "thesis.tex" ***
%%% End: ***
